{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from osgeo import gdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT_DIR = \"/Volumes/X/Data/fusion-s1-s2/\"\n",
    "S2_ROOT_PATH = f\"{DATA_ROOT_DIR}s2/sre-10m/\"\n",
    "ORBIT = \"044\"\n",
    "S1_ROOT_PATH = f\"{DATA_ROOT_DIR}s1db/32VNH/threeband/{ORBIT}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_date(target_date, date_array):\n",
    "    target = datetime.strptime(target_date, '%Y%m%d')\n",
    "    date_array = [datetime.strptime(date, '%Y%m%d') for date in date_array]\n",
    "    closest_date = min(date_array, key=lambda x: abs(target - x))\n",
    "    return closest_date.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_difference(date1, date2):\n",
    "    d1 = datetime.strptime(date1, '%Y%m%d')\n",
    "    d2 = datetime.strptime(date2, '%Y%m%d')\n",
    "    difference = abs(d1 - d2)\n",
    "\n",
    "    # Convert the difference to 'YYYYMMDD' format\n",
    "    years = difference.days // 365\n",
    "    months = (difference.days % 365) // 30\n",
    "    days = (difference.days % 365) % 30\n",
    "\n",
    "    return f'{years:04d}{months:02d}{days:02d}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/candidates_filtered_water_MAXED.json\", \"r\") as f:\n",
    "    candidates = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_date(target_date, date_array):\n",
    "    target = datetime.strptime(target_date, '%Y%m%d')\n",
    "    date_array = [d for d in date_array if \"Store\" not in d]\n",
    "    date_array = [datetime.strptime(date, '%Y%m%d') for date in date_array]\n",
    "    closest_date = min(date_array, key=lambda x: abs(target - x))\n",
    "    return closest_date.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_date_before(target_date, date_array):\n",
    "    target = datetime.strptime(target_date, '%Y%m%d')\n",
    "    date_array = [d for d in date_array if \"Store\" not in d]\n",
    "    date_array = [datetime.strptime(date, '%Y%m%d') for date in date_array]\n",
    "    before_target = [date for date in date_array if date <= target]\n",
    "    try:\n",
    "        closest_date = max(before_target)\n",
    "    except:\n",
    "        closest_date = target\n",
    "    return closest_date.strftime('%Y%m%d')\n",
    "\n",
    "def closest_date_after(target_date, date_array):\n",
    "    target = datetime.strptime(target_date, '%Y%m%d')\n",
    "    date_array = [d for d in date_array if \"Store\" not in d]\n",
    "    date_array = [datetime.strptime(date, '%Y%m%d') for date in date_array]\n",
    "    after_target = [date for date in date_array if date > target]\n",
    "    try:\n",
    "        closest_date = min(after_target)\n",
    "    except:\n",
    "        closest_date = target\n",
    "    return closest_date.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_TRAIN, DATASET_TEST, DATASET = {}, {}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_dates = [d.split(\"_\")[-1] for d in os.listdir(f\"data/cropped/s1/\")]\n",
    "idx = 0\n",
    "\n",
    "for k, v in candidates.items():\n",
    "    cloudy = v[\"cloudy\"]\n",
    "    cloudy_name = \"_\".join(v[\"cloudy\"].split(\"_\")[:3])\n",
    "\n",
    "    cloud_free = v[\"cloud_free\"]\n",
    "    cloud_free_name = \"_\".join(v[\"cloud_free\"].split(\"_\")[:3])\n",
    "    date_cloudy = cloudy.split(\"_\")[2]\n",
    "\n",
    "    s1_date = closest_date(date_cloudy, s1_dates)\n",
    "    after_date = closest_date_after(date_cloudy, s1_dates)\n",
    "    before_date = closest_date_before(date_cloudy, s1_dates)\n",
    "\n",
    "    TEMP_DATASET = {\n",
    "        \"s2_cloudy_B02\": f\"data/cropped/s2/{cloudy_name}/{cloudy_name}_B02/{'_'.join(cloudy.split('_')[:3])}_B02_{'_'.join(cloudy.split('_')[3:])}\",\n",
    "        \"s2_cloudy_B03\": f\"data/cropped/s2/{cloudy_name}/{cloudy_name}_B03/{'_'.join(cloudy.split('_')[:3])}_B03_{'_'.join(cloudy.split('_')[3:])}\",\n",
    "        \"s2_cloudy_B04\": f\"data/cropped/s2/{cloudy_name}/{cloudy_name}_B04/{'_'.join(cloudy.split('_')[:3])}_B04_{'_'.join(cloudy.split('_')[3:])}\",\n",
    "        \"s2_cloudy_B05\": f\"data/cropped/s2/{cloudy_name}/{cloudy_name}_B05/{'_'.join(cloudy.split('_')[:3])}_B05_{'_'.join(cloudy.split('_')[3:])}\",\n",
    "        \"s2_cloudy_B06\": f\"data/cropped/s2/{cloudy_name}/{cloudy_name}_B06/{'_'.join(cloudy.split('_')[:3])}_B06_{'_'.join(cloudy.split('_')[3:])}\",\n",
    "        \"s2_cloudy_B07\": f\"data/cropped/s2/{cloudy_name}/{cloudy_name}_B07/{'_'.join(cloudy.split('_')[:3])}_B07_{'_'.join(cloudy.split('_')[3:])}\",\n",
    "        \"s2_cloudy_B08\": f\"data/cropped/s2/{cloudy_name}/{cloudy_name}_B08/{'_'.join(cloudy.split('_')[:3])}_B08_{'_'.join(cloudy.split('_')[3:])}\",\n",
    "        \"s2_cloudy_B8A\": f\"data/cropped/s2/{cloudy_name}/{cloudy_name}_B8A/{'_'.join(cloudy.split('_')[:3])}_B8A_{'_'.join(cloudy.split('_')[3:])}\",\n",
    "        \"s2_cloudy_B11\": f\"data/cropped/s2/{cloudy_name}/{cloudy_name}_B11/{'_'.join(cloudy.split('_')[:3])}_B11_{'_'.join(cloudy.split('_')[3:])}\",\n",
    "        \"s2_cloudy_B12\": f\"data/cropped/s2/{cloudy_name}/{cloudy_name}_B12/{'_'.join(cloudy.split('_')[:3])}_B12_{'_'.join(cloudy.split('_')[3:])}\",\n",
    "        \"s2_cloud_free_B02\": f\"data/cropped/s2/{cloud_free_name}/{cloud_free_name}_B02/{'_'.join(cloud_free.split('_')[:3])}_B02_{'_'.join(cloud_free.split('_')[3:])}\",\n",
    "        \"s2_cloud_free_B03\": f\"data/cropped/s2/{cloud_free_name}/{cloud_free_name}_B03/{'_'.join(cloud_free.split('_')[:3])}_B03_{'_'.join(cloud_free.split('_')[3:])}\",\n",
    "        \"s2_cloud_free_B04\": f\"data/cropped/s2/{cloud_free_name}/{cloud_free_name}_B04/{'_'.join(cloud_free.split('_')[:3])}_B04_{'_'.join(cloud_free.split('_')[3:])}\",\n",
    "        \"s2_cloud_free_B05\": f\"data/cropped/s2/{cloud_free_name}/{cloud_free_name}_B05/{'_'.join(cloud_free.split('_')[:3])}_B05_{'_'.join(cloud_free.split('_')[3:])}\",\n",
    "        \"s2_cloud_free_B06\": f\"data/cropped/s2/{cloud_free_name}/{cloud_free_name}_B06/{'_'.join(cloud_free.split('_')[:3])}_B06_{'_'.join(cloud_free.split('_')[3:])}\",\n",
    "        \"s2_cloud_free_B07\": f\"data/cropped/s2/{cloud_free_name}/{cloud_free_name}_B07/{'_'.join(cloud_free.split('_')[:3])}_B07_{'_'.join(cloud_free.split('_')[3:])}\",\n",
    "        \"s2_cloud_free_B08\": f\"data/cropped/s2/{cloud_free_name}/{cloud_free_name}_B08/{'_'.join(cloud_free.split('_')[:3])}_B08_{'_'.join(cloud_free.split('_')[3:])}\",\n",
    "        \"s2_cloud_free_B8A\": f\"data/cropped/s2/{cloud_free_name}/{cloud_free_name}_B8A/{'_'.join(cloud_free.split('_')[:3])}_B8A_{'_'.join(cloud_free.split('_')[3:])}\",\n",
    "        \"s2_cloud_free_B11\": f\"data/cropped/s2/{cloud_free_name}/{cloud_free_name}_B11/{'_'.join(cloud_free.split('_')[:3])}_B11_{'_'.join(cloud_free.split('_')[3:])}\",\n",
    "        \"s2_cloud_free_B12\": f\"data/cropped/s2/{cloud_free_name}/{cloud_free_name}_B12/{'_'.join(cloud_free.split('_')[:3])}_B12_{'_'.join(cloud_free.split('_')[3:])}\",\n",
    "        \"s1_hv\": f\"data/cropped/s1/S1_32VNH_{s1_date}/S1_32VNH_{s1_date}_HV/S1_32VNH_{s1_date}_HV_{'_'.join(cloudy.split('_')[3:])}\",\n",
    "        \"s1_vv\": f\"data/cropped/s1/S1_32VNH_{s1_date}/S1_32VNH_{s1_date}_VV/S1_32VNH_{s1_date}_VV_{'_'.join(cloudy.split('_')[3:])}\",\n",
    "        \"s1_hv_-1\":f\"data/cropped/s1/S1_32VNH_{s1_date}/S1_32VNH_{before_date}_HV/S1_32VNH_{before_date}_HV_{'_'.join(cloudy.split('_')[3:])}\",\n",
    "        \"s1_hv_+1\":f\"data/cropped/s1/S1_32VNH_{s1_date}/S1_32VNH_{after_date}_HV/S1_32VNH_{after_date}_HV_{'_'.join(cloudy.split('_')[3:])}\",\n",
    "        \"s1_vv_-1\":f\"data/cropped/s1/S1_32VNH_{s1_date}/S1_32VNH_{before_date}_HV/S1_32VNH_{before_date}_HV_{'_'.join(cloudy.split('_')[3:])}\",\n",
    "        \"s1_vv_+1\":f\"data/cropped/s1/S1_32VNH_{s1_date}/S1_32VNH_{after_date}_HV/S1_32VNH_{after_date}_HV_{'_'.join(cloudy.split('_')[3:])}\",\n",
    "    }\n",
    "\n",
    "    if all([os.path.isfile(tv) for tv in TEMP_DATASET.values()]):\n",
    "        DATASET[idx] = TEMP_DATASET\n",
    "        idx += 1\n",
    "\n",
    "with open(\"data/dataset_filtered_water_timeseries.json\", \"w\") as f:\n",
    "    json.dump(DATASET, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate dataset\n",
    "with open(\"data/dataset_filtered_water_timeseries.json\", \"r\") as f:\n",
    "    DATASET = json.load(f)\n",
    "    \n",
    "dataset_keys = list(DATASET.keys())\n",
    "np.random.shuffle(dataset_keys)\n",
    "split_index = int(0.9 * len(dataset_keys))\n",
    "\n",
    "dataset_keys_train = dataset_keys[:split_index]\n",
    "dataset_keys_test = dataset_keys[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for k in dataset_keys_train:\n",
    "    DATASET_TRAIN[i] = DATASET[k]\n",
    "    i += 1\n",
    "\n",
    "with open(\"data/dataset_filtered_water_timeseries_train.json\", \"w\") as f:\n",
    "    json.dump(DATASET_TRAIN, f)\n",
    "\n",
    "l = 0\n",
    "for k in dataset_keys_test:\n",
    "    DATASET_TEST[l] = DATASET[k]\n",
    "    l += 1\n",
    "with open(\"data/dataset_filtered_water_timeseries_test.json\", \"w\") as f:\n",
    "    json.dump(DATASET_TEST, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "452"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DATASET_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
